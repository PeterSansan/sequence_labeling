{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:59: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# 第一版中文分词程序：单向lstm\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "word_size = 128\n",
    "maxlen = 32\n",
    "s = open('msr_train_p.txt').read().decode('gbk')\n",
    "s = s.split('\\r\\n')\n",
    "\n",
    "def clean(s): #整理一下数据，有些不规范的地方\n",
    "    if u'“/s' not in s:\n",
    "        return s.replace(u' ”/s', '')\n",
    "    elif u'”/s' not in s:\n",
    "        return s.replace(u'“/s ', '')\n",
    "    elif u'‘/s' not in s:\n",
    "        return s.replace(u' ’/s', '')\n",
    "    elif u'’/s' not in s:\n",
    "        return s.replace(u'‘/s ', '')\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "s = u''.join(map(clean, s))\n",
    "s = re.split(u'[，。！？、]/[bems]', s)\n",
    "\n",
    "data = [] #生成训练样本\n",
    "label = []\n",
    "def get_xy(s):\n",
    "    s = re.findall('(.)/(.)', s)\n",
    "    if s:\n",
    "        s = np.array(s)\n",
    "        return list(s[:,0]), list(s[:,1])\n",
    "\n",
    "for i in s:\n",
    "    x = get_xy(i)\n",
    "    if x:\n",
    "        data.append(x[0])\n",
    "        label.append(x[1])\n",
    "\n",
    "d = pd.DataFrame(index=range(len(data)))\n",
    "d['data'] = data\n",
    "d['label'] = label\n",
    "d = d[d['data'].apply(len) <= maxlen]\n",
    "d.index = range(len(d))\n",
    "tag = pd.Series({'s':0, 'b':1, 'm':2, 'e':3, 'x':4})\n",
    "\n",
    "\n",
    "chars = [] #统计所有字，跟每个字编号\n",
    "for i in data:\n",
    "    chars.extend(i)\n",
    "\n",
    "chars = pd.Series(chars).value_counts()\n",
    "chars[:] = range(1, len(chars)+1)\n",
    "\n",
    "#生成适合模型输入的格式\n",
    "from keras.utils import np_utils\n",
    "d['x'] = d['data'].apply(lambda x: np.array(list(chars[x])+[0]*(maxlen-len(x))))\n",
    "d['y'] = d['label'].apply(lambda x: np.array(map(lambda y:np_utils.to_categorical(y,5), tag[x].reshape((-1,1)))+[np.array([[0,0,0,0,1]])]*(maxlen-len(x))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289458\n",
      "[  8  45 322  90  38 200   7   2  43 165 126 247   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[[[ 0.  1.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  1.  0.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  1.  0.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(len(d['x']))\n",
    "print(d['x'][0])\n",
    "print(d['y'][0])\n",
    "\n",
    "d['x'] = np.array(list(d['x']))\n",
    "d['y'] = np.array(list(d['y'])).reshape((-1,maxlen,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设计模型\n",
    "word_size = 128\n",
    "maxlen = 32\n",
    "from keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "sequence = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded = Embedding(len(chars)+1, word_size, input_length=maxlen, mask_zero=True)(sequence)\n",
    "blstm = Bidirectional(LSTM(64, return_sequences=True), merge_mode='sum')(embedded)\n",
    "output = TimeDistributed(Dense(5, activation='softmax'))(blstm)\n",
    "model = Model(input=sequence, output=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 1024\n",
    "history = model.fit(d['x'], , batch_size=batch_size, nb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#转移概率，单纯用了等概率\n",
    "zy = {'be':0.5, \n",
    "      'bm':0.5, \n",
    "      'eb':0.5, \n",
    "      'es':0.5, \n",
    "      'me':0.5, \n",
    "      'mm':0.5,\n",
    "      'sb':0.5, \n",
    "      'ss':0.5\n",
    "     }\n",
    "\n",
    "zy = {i:np.log(zy[i]) for i in zy.keys()}\n",
    "\n",
    "def viterbi(nodes):\n",
    "    paths = {'b':nodes[0]['b'], 's':nodes[0]['s']}\n",
    "    for l in range(1,len(nodes)):\n",
    "        paths_ = paths.copy()\n",
    "        paths = {}\n",
    "        for i in nodes[l].keys():\n",
    "            nows = {}\n",
    "            for j in paths_.keys():\n",
    "                if j[-1]+i in zy.keys():\n",
    "                    nows[j+i]= paths_[j]+nodes[l][i]+zy[j[-1]+i]\n",
    "            k = np.argmax(nows.values())\n",
    "            paths[nows.keys()[k]] = nows.values()[k]\n",
    "    return paths.keys()[np.argmax(paths.values())]\n",
    "\n",
    "def simple_cut(s):\n",
    "    if s:\n",
    "        r = model.predict(np.array([list(chars[list(s)].fillna(0).astype(int))+[0]*(maxlen-len(s))]), verbose=False)[0][:len(s)]\n",
    "        r = np.log(r)\n",
    "        nodes = [dict(zip(['s','b','m','e'], i[:4])) for i in r]\n",
    "        t = viterbi(nodes)\n",
    "        words = []\n",
    "        for i in range(len(s)):\n",
    "            if t[i] in ['s', 'b']:\n",
    "                words.append(s[i])\n",
    "            else:\n",
    "                words[-1] += s[i]\n",
    "        return words\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "not_cuts = re.compile(u'([\\da-zA-Z ]+)|[。，、？！\\.\\?,!]')\n",
    "def cut_word(s):\n",
    "    result = []\n",
    "    j = 0\n",
    "    for i in not_cuts.finditer(s):\n",
    "        result.extend(simple_cut(s[j:i.start()]))\n",
    "        result.append(s[i.start():i.end()])\n",
    "        j = i.end()\n",
    "    result.extend(simple_cut(s[j:]))\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
