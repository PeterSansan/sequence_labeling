{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、把汉字与标签分开\n",
    "```\n",
    "  输入：['中/b','国/e']\n",
    "  输出：\n",
    "     data = ['中','国']\n",
    "     label = ['b','e']\n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(s):  # 把汉字与标签分开\n",
    "    s = re.findall('(.)/(.)', s)\n",
    "    if s:\n",
    "        s = np.array(s)\n",
    "        return list(s[:,0]), list(s[:,1])\n",
    "    \n",
    "def split_data_label(ss):\n",
    "    data = [] \n",
    "    label = []\n",
    "    for i in ss:  \n",
    "        x = get_xy(i)\n",
    "        if x:\n",
    "            data.append(x[0])\n",
    "            label.append(x[1])\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、准确率，召回率，F1的计算\n",
    "```\n",
    "输入：\n",
    "    sen1 = ['我', '从来', '没有','说', '不', '喜欢', '你']  # 正确的\n",
    "    sen2 = ['我', '从', '来','没','有','说','不','喜欢', '你'] # 预测的\n",
    "输出：\n",
    "   (0.6250000000000001, 0.7142857142857143, 0.5555555555555556)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation(sen1,sen2):\n",
    "    # 1、计算正确的词数\n",
    "    TP = 0\n",
    "    i = 0 # 句子0词的索引\n",
    "    j = 0 # 句子1词的索引\n",
    "    \n",
    "    ii = 0 # 句子0字的索引\n",
    "    jj = 0 # 句子1字的索引\n",
    "    \n",
    "    \n",
    "    while i < len(sen1):\n",
    "        if sen1[i] == sen2[j] and ii == jj :  # 找到的情况下\n",
    "            ii+=len(sen1[i])\n",
    "            jj+=len(sen2[j])\n",
    "            i+=1\n",
    "            j+=1\n",
    "            TP+=1\n",
    "        elif sen1[i] != sen2[j] and ii ==jj:\n",
    "            ii+=len(sen1[i])\n",
    "            jj+=len(sen2[j])\n",
    "        else:\n",
    "            if ii>jj:  # sen1词长于sen2 [我 喜欢 广州]  [我 喜 欢 广州]\n",
    "                j+=1\n",
    "                jj += len(sen2[j])\n",
    "            else:  \n",
    "                i+=1\n",
    "                ii += len(sen1[i])\n",
    "            if ii==jj:\n",
    "                i+=1\n",
    "                j+=1\n",
    "        #print(\"i = %d,j = %d, ii = %d, jj = %d, TP = %d sen1[i] = %s, sen2[j] = %s\"%(i,j,ii,jj,TP,sen1[i],sen2[j]))\n",
    "    # 2、计算准确率、召回率、F1值\n",
    "    m = len(sen2)  # 注意再错了\n",
    "    n = len(sen1)\n",
    "    \n",
    "    precision = TP/m\n",
    "    recall = TP/n\n",
    "    f1 = 2*TP/(m+n)\n",
    "    return f1,precision,recall,TP,m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sen1 = ['我', '喜欢', '广州']\n",
    "#sen2 = ['我', '喜','欢','广州']\n",
    "#print(sen2[2])\n",
    "#calculate_evaluation(sen1,sen2)\n",
    "#sen1 = ['他', '来到', '中国', '，', '成为', '第一个', '访', '华', '的', '大', '船主', '。']\n",
    "#sen2 = ['他来', '到中', '国，', '成为', '第一', '个访', '华的', '大船', '主', '。']\n",
    "#calculate_evaluation(sen1,sen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、批量计算准确率、召回率、F1值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_batch(data1,data2):\n",
    "    M = 0\n",
    "    N = 0\n",
    "    TP_S = 0\n",
    "    for i,sen in enumerate(data1):\n",
    "        f1,precision,recall,TP,m,n = calculate_evaluation(sen,data2[i])\n",
    "        TP_S += TP\n",
    "        M += m\n",
    "        N += n\n",
    "    F1 = 2*TP_S/(M+N)\n",
    "    P = TP_S/M\n",
    "    R = TP_S/N\n",
    "    return F1,P,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、数据标签转为词的集合\n",
    "```\n",
    "输入：\n",
    "    data_x = [['我','从','来','没','有','说','不','喜','欢','你'],[...]]  |   data_x = ['我','从',...] \n",
    "    data_y = [['s','b','e','b','e','s','s','b','e','s'],[...]]                  |   data_y = ['s','b',...]\n",
    "    op = [0|1]m= # 0表示两维数组  # 1表示一维数组\n",
    "输出：\n",
    "    sen_reorganization = ['我', '从来', '没有','说', '不', '喜欢', '你']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_label_to_word(data_x,data_y,op):\n",
    "    sen_reorganization = []\n",
    "    for i,sens in enumerate(data_x):\n",
    "        sen_tmp = []\n",
    "        for j,char in enumerate(sens):\n",
    "            if data_y[i][j] == 's':\n",
    "                sen_tmp.append(char)\n",
    "            elif data_y[i][j] == 'b':\n",
    "                new_word = ''\n",
    "                new_word+=char\n",
    "            elif data_y[i][j] == 'm':\n",
    "                new_word+=char\n",
    "            else:\n",
    "                new_word+=char\n",
    "                sen_tmp.append(new_word)\n",
    "        sen_reorganization.append(sen_tmp)\n",
    "    return sen_reorganization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、模型中文分词预测函数\n",
    "```\n",
    "输入：\n",
    "    预测出每个类的概率，两维，一个句子(已取对数)，如test_x = [ [-1.23 -1.2 -23.3 -0.4 -0],[-2.3 -2.1 -1.2 -2.2 -0.2]];\n",
    "输出：\n",
    "    ['b','e','s',...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cws_pre(data_x):\n",
    "    obs = data_x # 输入为发射概率矩阵\n",
    "    dict_c = {0:'s',1:'b',2:'m',3:'e',4:'x'}\n",
    "    #转移概率，单纯用了等概率,后面要对数据进行统计\n",
    "    ee = 1e-300\n",
    "    A = np.array([[0.5,0.5,ee,ee], # 一般情况下的状态转移矩阵\n",
    "        [ee,ee,0.5,0.5],\n",
    "        [ee,ee,0.5,0.5],\n",
    "        [0.5,0.5,ee,ee]])\n",
    "    \n",
    "    for i,x in enumerate(A):   # 对数化\n",
    "        for j,y in enumerate(x):\n",
    "            A[i][j] = np.log(y)   \n",
    "    # 维特比算法\n",
    "\n",
    "    max_p = [0.5,0.5,1e-323,1e-323] # [max] 存储当前最大的概率 ，分别为每条路上的路径, 初始化为初始概率\n",
    "    max_p = [np.log(x) for x in max_p]\n",
    "    pathx = []    # 存储路径，一共有4条路径\n",
    "\n",
    "    #　第一个字判断\n",
    "\n",
    "    for i in range(4):\n",
    "        max_p[i] = max_p[i]+obs[0][i]\n",
    "        pathx.append([i])\n",
    "    # 后面的字\n",
    "    for i in range(len(obs)-2): \n",
    "        max_p_new = np.zeros(4) # 暂时存储最大概率\n",
    "        pathx_new = [[0],[0],[0],[0]] #暂时存储路径\n",
    "        for j in range(4): # 扫描当前的状态\n",
    "            pro_max_tmp = -10000  # 很小的值就可以\n",
    "            for k in range(4): # 扫描前面的4个最有可能的路径\n",
    "                pro =  max_p[k] + A[k][j] + obs[i+1][j] \n",
    "                if pro > pro_max_tmp:\n",
    "                    pro_max_tmp = pro   \n",
    "                    path_tmp = copy.deepcopy(pathx[k])\n",
    "                    path_tmp.append(j)\n",
    "            max_p_new[j] = pro_max_tmp# 更新最大概率\n",
    "            pathx_new[j] = path_tmp# 更新路径\n",
    "        max_p = max_p_new\n",
    "        pathx = pathx_new\n",
    "    # 最后一个字的特殊处理，只有两种选择，即S与E\n",
    "    # 最后一个是S的情况,两种情况，s -> s, e -> s\n",
    "    p = np.array([-1000.0,-1000.0,-1000.0,-1000.0])\n",
    "    if max_p[0] >= max_p[3]:\n",
    "        p[0] = max_p[0]\n",
    "        pathx[0].append(0)\n",
    "    else:\n",
    "        p[0] = max_p[3]\n",
    "        pathx[3].append(0)\n",
    "        pathx[0] = pathx[3]\n",
    "        \n",
    "    if max_p[1] >= max_p[2]:\n",
    "        p[3] = max_p[1]\n",
    "        pathx[1].append(3)\n",
    "        pathx[3] = pathx[1]\n",
    "    else:\n",
    "        p[3] = max_p[2]\n",
    "        pathx[2].append(3)\n",
    "        pathx[3] = pathx[2]\n",
    "    # 最后留下概率最大的路径\n",
    "    pro_max_tmp = -10000\n",
    "    num = np.argmax(p)\n",
    "    pathx = pathx[num]\n",
    "    pathx = [dict_c[x] for x in pathx]\n",
    "    return pathx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、批量数据预测函数\n",
    "```\n",
    "输入：\n",
    "    预测出每个类的概率，三维，多个句子（已取对数），如test_x = [[[-1.23 -1.2 -23.3 -0.4 -0],[-2.3 -2.1 -1.2 -2.2 -0.2],[[...]]];\n",
    "输出：\n",
    "    [['s','b','e'],[...]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cws_pre_batch(data):\n",
    "    labels = []\n",
    "    for i,sen in enumerate(data):\n",
    "        path = cws_pre(sen)\n",
    "        labels.append(path)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nxx = 1e-200\\na = np.array([[xx,xx,0.999,xx,xx],\\n              [xx,xx,0.999,xx,xx],\\n              [xx,xx,0.999,xx,xx],\\n              [xx,ee,ee,0.99,xx],\\n              [0.99,xx,xx,xx,xx]])\\n\\nfor i,x in enumerate(a):\\n    for j,y in enumerate(x):\\n        a[i][j] = np.log(y)\\n\\nresult = cws_pre(a)\\nprint(result)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "xx = 1e-200\n",
    "a = np.array([[xx,xx,0.999,xx,xx],\n",
    "              [xx,xx,0.999,xx,xx],\n",
    "              [xx,xx,0.999,xx,xx],\n",
    "              [xx,ee,ee,0.99,xx],\n",
    "              [0.99,xx,xx,xx,xx]])\n",
    "\n",
    "for i,x in enumerate(a):\n",
    "    for j,y in enumerate(x):\n",
    "        a[i][j] = np.log(y)\n",
    "\n",
    "result = cws_pre(a)\n",
    "print(result)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
