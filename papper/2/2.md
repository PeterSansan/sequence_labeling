## End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF 

这篇文章的亮点是用CNN来提取字符特征

<!--more-->

### 0、模型

![](http://ogtxggxo6.bkt.clouddn.com/asw.png?imagesoim)

CNN、LSTM输入输出都加了 dropout;

### 1、参数初始化

本实验对比了三个预先训练好的词向量，[GloVe 100-dimensional embeddings ](http://nlp.stanford.edu/projects/glove/ ); [Senna 50-dimensional embeddings ](http://ronan.collobert.com/senna/ );[Google’s Word2Vec 300-dimensional embeddings ](https://code.google.com/archive/p/word2vec/ ); 也对比了没有初始化的词向量，初始化的范围如下：



![](http://ogtxggxo6.bkt.clouddn.com/rty.png?imagesoim)

根据

![](http://ogtxggxo6.bkt.clouddn.com/opt.png?imagesoim)

学习速率：



![](http://ogtxggxo6.bkt.clouddn.com/hge.png?imagesoim)

### 2、实验结果

#### 2.1、自己实验的模型结果对比

![](http://ogtxggxo6.bkt.clouddn.com/nnv.png?imagesoim)

#### 2.2、与其他论文对比结果

![](http://ogtxggxo6.bkt.clouddn.com/xsw.png?imageslim)

#### 2.3、词向量对比结果

![](http://ogtxggxo6.bkt.clouddn.com/zxc.png?imageslim)

这里显示Glove的效果有好一些