{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWS_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "word_size = 128\n",
    "maxlen = 32\n",
    "s = open('./../dataset/msr_train.txt').read().decode('gbk')\n",
    "s = s.split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(s): #整理一下数据，有些不规范的地方\n",
    "    if u'“/s' not in s:\n",
    "        return s.replace(u' ”/s', '')\n",
    "    elif u'”/s' not in s:\n",
    "        return s.replace(u'“/s ', '')\n",
    "    elif u'‘/s' not in s:\n",
    "        return s.replace(u' ’/s', '')\n",
    "    elif u'’/s' not in s:\n",
    "        return s.replace(u'‘/s ', '')\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = u''.join(map(clean, s))\n",
    "s = re.split(u'[，。！？、]/[bems]', s)\n",
    "\n",
    "data = [] #生成训练样本\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xy(s):\n",
    "    s = re.findall('(.)/(.)', s)\n",
    "    if s:\n",
    "        s = np.array(s)\n",
    "        return list(s[:,0]), list(s[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in s:\n",
    "    x = get_xy(i)\n",
    "    if x:\n",
    "        data.append(x[0])\n",
    "        label.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#转移概率，单纯用了等概率\n",
    "zy = {'be':0.5, \n",
    "      'bm':0.5, \n",
    "      'eb':0.5, \n",
    "      'es':0.5, \n",
    "      'me':0.5, \n",
    "      'mm':0.5,\n",
    "      'sb':0.5, \n",
    "      'ss':0.5\n",
    "     }\n",
    "\n",
    "zy = {i:np.log(zy[i]) for i in zy.keys()}\n",
    "\n",
    "def viterbi(nodes):\n",
    "    paths = {'b':nodes[0]['b'], 's':nodes[0]['s']}\n",
    "    for l in range(1,len(nodes)):\n",
    "        paths_ = paths.copy()\n",
    "        paths = {}\n",
    "        for i in nodes[l].keys():\n",
    "            nows = {}\n",
    "            for j in paths_.keys():\n",
    "                if j[-1]+i in zy.keys():\n",
    "                    nows[j+i]= paths_[j]+nodes[l][i]+zy[j[-1]+i]\n",
    "            k = np.argmax(nows.values())\n",
    "            paths[nows.keys()[k]] = nows.values()[k]\n",
    "    return paths.keys()[np.argmax(paths.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_cut(s):\n",
    "    if s:\n",
    "        r = model.predict(np.array([list(chars[list(s)].fillna(0).astype(int))+[0]*(maxlen-len(s))]), verbose=False)[0][:len(s)]\n",
    "        r = np.log(r)\n",
    "        nodes = [dict(zip(['s','b','m','e'], i[:4])) for i in r]\n",
    "        t = viterbi(nodes)\n",
    "        words = []\n",
    "        for i in range(len(s)):\n",
    "            if t[i] in ['s', 'b']:\n",
    "                words.append(s[i])\n",
    "            else:\n",
    "                words[-1] += s[i]\n",
    "        return words\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#转移概率，单纯用了等概率\n",
    "zy = {'be':0.5, \n",
    "      'bm':0.5, \n",
    "      'eb':0.5, \n",
    "      'es':0.5, \n",
    "      'me':0.5, \n",
    "      'mm':0.5,\n",
    "      'sb':0.5, \n",
    "      'ss':0.5\n",
    "     }\n",
    "\n",
    "zy = {i:np.log(zy[i]) for i in zy.keys()}\n",
    "\n",
    "def viterbi(nodes):\n",
    "    paths = {'b':nodes[0]['b'], 's':nodes[0]['s']}\n",
    "    for l in range(1,len(nodes)):\n",
    "        paths_ = paths.copy()\n",
    "        paths = {}\n",
    "        for i in nodes[l].keys():\n",
    "            nows = {}\n",
    "            for j in paths_.keys():\n",
    "                if j[-1]+i in zy.keys():\n",
    "                    nows[j+i]= paths_[j]+nodes[l][i]+zy[j[-1]+i]\n",
    "            k = np.argmax(nows.values())\n",
    "            paths[nows.keys()[k]] = nows.values()[k]\n",
    "    return paths.keys()[np.argmax(paths.values())]\n",
    "\n",
    "def simple_cut(s):\n",
    "    if s:\n",
    "        r = model.predict(np.array([list(chars[list(s)].fillna(0).astype(int))+[0]*(maxlen-len(s))]), verbose=False)[0][:len(s)]\n",
    "        r = np.log(r)\n",
    "        nodes = [dict(zip(['s','b','m','e'], i[:4])) for i in r]\n",
    "        t = viterbi(nodes)\n",
    "        words = []\n",
    "        for i in range(len(s)):\n",
    "            if t[i] in ['s', 'b']:\n",
    "                words.append(s[i])\n",
    "            else:\n",
    "                words[-1] += s[i]\n",
    "        return words\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "not_cuts = re.compile(u'([\\da-zA-Z ]+)|[。，、？！\\.\\?,!]')\n",
    "def cut_word(s):\n",
    "    result = []\n",
    "    j = 0\n",
    "    for i in not_cuts.finditer(s):\n",
    "        result.extend(simple_cut(s[j:i.start()]))\n",
    "        result.append(s[i.start():i.end()])\n",
    "        j = i.end()\n",
    "    result.extend(simple_cut(s[j:]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(index=range(len(data)))\n",
    "d['data'] = data\n",
    "d['label'] = label\n",
    "d = d[d['data'].apply(len) <= maxlen]\n",
    "d.index = range(len(d))\n",
    "tag = pd.Series({'s':0, 'b':1, 'm':2, 'e':3, 'x':4})\n",
    "\n",
    "\n",
    "chars = [] #统计所有字，跟每个字编号\n",
    "for i in data:\n",
    "    chars.extend(i)\n",
    "\n",
    "chars = pd.Series(chars).value_counts()\n",
    "chars[:] = range(1, len(chars)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成适合模型输入的格式\n",
    "d['x'] = d['data'].apply(lambda x: np.array(list(chars[x])+[0]*(maxlen-len(x))))\n",
    "d['y'] = d['label'].apply(lambda x: np.array(map(lambda y:np_utils.to_categorical(y,5), tag[x].values.reshape((-1,1)))+[np.array([[0,0,0,0,1]])]*(maxlen-len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 32, 128)           660864    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 32, 64)            98816     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 32, 5)             325       \n",
      "=================================================================\n",
      "Total params: 760,005\n",
      "Trainable params: 760,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#设计模型\n",
    "word_size = 128\n",
    "maxlen = 32\n",
    "\n",
    "sequence = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded = Embedding(len(chars)+1, word_size, input_length=maxlen, mask_zero=True)(sequence)\n",
    "blstm = Bidirectional(LSTM(64, return_sequences=True,implementation=1), merge_mode='sum')(embedded)\n",
    "output = TimeDistributed(Dense(5, activation='softmax'))(blstm)\n",
    "model = Model(inputs=sequence, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "86s - loss: 0.7370 - acc: 0.7131\n",
      "Epoch 2/50\n",
      "87s - loss: 0.4079 - acc: 0.8532\n",
      "Epoch 3/50\n",
      "87s - loss: 0.3471 - acc: 0.8753\n",
      "Epoch 4/50\n",
      "87s - loss: 0.3118 - acc: 0.8885\n",
      "Epoch 5/50\n",
      "87s - loss: 0.2861 - acc: 0.8983\n",
      "Epoch 6/50\n",
      "87s - loss: 0.2651 - acc: 0.9062\n",
      "Epoch 7/50\n",
      "88s - loss: 0.2478 - acc: 0.9126\n",
      "Epoch 8/50\n",
      "88s - loss: 0.2324 - acc: 0.9182\n",
      "Epoch 9/50\n",
      "89s - loss: 0.2191 - acc: 0.9230\n",
      "Epoch 10/50\n",
      "89s - loss: 0.2072 - acc: 0.9274\n",
      "Epoch 11/50\n",
      "89s - loss: 0.1968 - acc: 0.9312\n",
      "Epoch 12/50\n",
      "89s - loss: 0.1874 - acc: 0.9345\n",
      "Epoch 13/50\n",
      "89s - loss: 0.1787 - acc: 0.9378\n",
      "Epoch 14/50\n",
      "89s - loss: 0.1708 - acc: 0.9407\n",
      "Epoch 15/50\n",
      "89s - loss: 0.1637 - acc: 0.9433\n",
      "Epoch 16/50\n",
      "89s - loss: 0.1570 - acc: 0.9459\n",
      "Epoch 17/50\n",
      "90s - loss: 0.1509 - acc: 0.9479\n",
      "Epoch 18/50\n",
      "90s - loss: 0.1450 - acc: 0.9502\n",
      "Epoch 19/50\n",
      "90s - loss: 0.1394 - acc: 0.9522\n",
      "Epoch 20/50\n",
      "90s - loss: 0.1346 - acc: 0.9540\n",
      "Epoch 21/50\n",
      "90s - loss: 0.1296 - acc: 0.9558\n",
      "Epoch 22/50\n",
      "90s - loss: 0.1251 - acc: 0.9574\n",
      "Epoch 23/50\n",
      "89s - loss: 0.1207 - acc: 0.9591\n",
      "Epoch 24/50\n",
      "90s - loss: 0.1168 - acc: 0.9605\n",
      "Epoch 25/50\n",
      "90s - loss: 0.1127 - acc: 0.9620\n",
      "Epoch 26/50\n",
      "90s - loss: 0.1093 - acc: 0.9632\n",
      "Epoch 27/50\n",
      "90s - loss: 0.1056 - acc: 0.9645\n",
      "Epoch 28/50\n",
      "90s - loss: 0.1024 - acc: 0.9656\n",
      "Epoch 29/50\n",
      "90s - loss: 0.0991 - acc: 0.9668\n",
      "Epoch 30/50\n",
      "89s - loss: 0.0963 - acc: 0.9679\n",
      "Epoch 31/50\n",
      "89s - loss: 0.0933 - acc: 0.9689\n",
      "Epoch 32/50\n",
      "89s - loss: 0.0906 - acc: 0.9699\n",
      "Epoch 33/50\n",
      "89s - loss: 0.0878 - acc: 0.9709\n",
      "Epoch 34/50\n",
      "90s - loss: 0.0852 - acc: 0.9718\n",
      "Epoch 35/50\n",
      "89s - loss: 0.0826 - acc: 0.9727\n",
      "Epoch 36/50\n",
      "89s - loss: 0.0803 - acc: 0.9735\n",
      "Epoch 37/50\n",
      "89s - loss: 0.0780 - acc: 0.9744\n",
      "Epoch 38/50\n",
      "88s - loss: 0.0758 - acc: 0.9751\n",
      "Epoch 39/50\n",
      "88s - loss: 0.0737 - acc: 0.9759\n",
      "Epoch 40/50\n",
      "88s - loss: 0.0718 - acc: 0.9765\n",
      "Epoch 41/50\n",
      "89s - loss: 0.0697 - acc: 0.9773\n",
      "Epoch 42/50\n",
      "89s - loss: 0.0679 - acc: 0.9778\n",
      "Epoch 43/50\n",
      "88s - loss: 0.0659 - acc: 0.9786\n",
      "Epoch 44/50\n",
      "89s - loss: 0.0640 - acc: 0.9793\n",
      "Epoch 45/50\n",
      "88s - loss: 0.0623 - acc: 0.9798\n",
      "Epoch 46/50\n",
      "88s - loss: 0.0607 - acc: 0.9804\n",
      "Epoch 47/50\n",
      "88s - loss: 0.0590 - acc: 0.9810\n",
      "Epoch 48/50\n",
      "88s - loss: 0.0575 - acc: 0.9815\n",
      "Epoch 49/50\n",
      "88s - loss: 0.0558 - acc: 0.9820\n",
      "Epoch 50/50\n",
      "88s - loss: 0.0545 - acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "history = model.fit(np.array(list(d['x'])), np.array(list(d['y'])).reshape((-1,maxlen,5)),\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=2,\n",
    "                    epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
